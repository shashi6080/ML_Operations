{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Rescaling Numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescale numerical data data to be between teo values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-500.5],\n",
       "       [-100.1],\n",
       "       [   0. ],\n",
       "       [ 100.1],\n",
       "       [ 900.9]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "feature = np.array([[-500.5], [-100.1], [0], [100.1], [900.9]])\n",
    "\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.28571429],\n",
       "       [0.35714286],\n",
       "       [0.42857143],\n",
       "       [1.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "scaled_feature = minmax_scale.fit_transform(feature)\n",
    "\n",
    "scaled_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Standardize a feature(Numerical data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform a feature to have mean 0 and standard deviation of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-900.5],\n",
       "       [-250.5],\n",
       "       [ 150.9],\n",
       "       [ 711.9],\n",
       "       [9999.1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "feature = np.array([[-900.5], [-250.5], [150.9], [711.9], [9999.1]])\n",
    "\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.69971382],\n",
       "       [-0.53971903],\n",
       "       [-0.4409161 ],\n",
       "       [-0.30282829],\n",
       "       [ 1.98317724]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_scaler = preprocessing.StandardScaler()\n",
    "\n",
    "scaled_feature = standard_scaler.fit_transform(feature)\n",
    "\n",
    "scaled_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Normalizing observations(Numerical data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescale the feature values of observations to have unit norm (total length of 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4 ,  0.4 ],\n",
       "       [ 1.5 ,  3.5 ],\n",
       "       [ 1.2 , 15.5 ],\n",
       "       [ 1.89, 38.9 ],\n",
       "       [20.2 ,  5.2 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "feature = np.array([[0.4, 0.4], [1.5, 3.5], [1.2, 15.5], [1.89, 38.9], [20.2, 5.2]])\n",
    "\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70710678, 0.70710678],\n",
       "       [0.3939193 , 0.91914503],\n",
       "       [0.07718838, 0.99701653],\n",
       "       [0.04852887, 0.99882178],\n",
       "       [0.96842682, 0.24929799]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L2 normalizing\n",
    "normalizer = preprocessing.Normalizer(norm='l2')\n",
    "\n",
    "normalized_feature = normalizer.transform(feature)\n",
    "\n",
    "normalized_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.5       ],\n",
       "       [0.3       , 0.7       ],\n",
       "       [0.07185629, 0.92814371],\n",
       "       [0.04633489, 0.95366511],\n",
       "       [0.79527559, 0.20472441]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L1 normalizing\n",
    "normalizer = preprocessing.Normalizer(norm='l1')\n",
    "\n",
    "normalized_feature = normalizer.transform(feature)\n",
    "\n",
    "normalized_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generate Polynomial and Intercation features(Numerical data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial features are often created when we want to include the notion that there exists a nonlinear relationship between the features and the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 3., 4., 6., 9.],\n",
       "       [2., 3., 4., 6., 9.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "features = np.array([[2, 3], [2, 3]])\n",
    "\n",
    "polynomial_interaction = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "transformed_features = polynomial_interaction.fit_transform(features)\n",
    "\n",
    "transformed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 3., 6.],\n",
       "       [2., 3., 6.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting interaction to True\n",
    "\n",
    "polynomial_interaction = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "\n",
    "transformed_features = polynomial_interaction.fit_transform(features)\n",
    "\n",
    "transformed_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Custom transforming features(Numerical data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom transformation to one or more features. We might want to create a feature that is the natural log of values of different feature. We can do this by creating a function and then mapping it to features using sklearn FunctionTransformer or pandas apply function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [2, 3],\n",
       "       [2, 3]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "features = np.array([[2, 3], [2, 3], [2, 3]])\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12, 13],\n",
       "       [12, 13],\n",
       "       [12, 13]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_ten(x):\n",
    "    return x+10\n",
    "\n",
    "ten_transformer = FunctionTransformer(add_ten)\n",
    "\n",
    "transformed_features = ten_transformer.transform(features)\n",
    "\n",
    "transformed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature1  feature2\n",
      "0         2         3\n",
      "1         2         3\n",
      "2         2         3\n",
      "\n",
      "\n",
      "Converted back to numpy array :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [2, 3],\n",
       "       [2, 3]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Alternate way using pandas\n",
    "df = pd.DataFrame(features, columns=['feature1', 'feature2'])\n",
    "\n",
    "df.apply(add_ten)\n",
    "\n",
    "print(df)\n",
    "print('\\n')\n",
    "\n",
    "# convert back to numpy array\n",
    "print('Converted back to numpy array :')\n",
    "df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Handling Outliers(Numerical data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 ways we can handle outliers.\n",
    "1. We can drop them\n",
    "2. We can include them as feature\n",
    "3. We can transform them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Square_Feet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>534433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392333</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4322032</td>\n",
       "      <td>116.0</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Rooms  Square_Feet\n",
       "0   534433    2.0         1500\n",
       "1   392333    3.5         2500\n",
       "2   293222    2.0         1500\n",
       "3  4322032  116.0        40000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a dataframe\n",
    "houses = pd.DataFrame()\n",
    "houses['Price'] = [534433, 392333, 293222, 4322032]\n",
    "houses['Rooms'] = [2, 3.5, 2, 116]\n",
    "houses['Square_Feet'] = [1500, 2500, 1500, 40000]\n",
    "\n",
    "houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Square_Feet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>534433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392333</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Price  Rooms  Square_Feet\n",
       "0  534433    2.0         1500\n",
       "1  392333    3.5         2500\n",
       "2  293222    2.0         1500"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First way, dropping the observation\n",
    "houses = houses[houses['Rooms'] < 20]\n",
    "houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Square_Feet</th>\n",
       "      <th>Outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>534433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392333</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4322032</td>\n",
       "      <td>116.0</td>\n",
       "      <td>40000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Rooms  Square_Feet  Outlier\n",
       "0   534433    2.0         1500        0\n",
       "1   392333    3.5         2500        0\n",
       "2   293222    2.0         1500        0\n",
       "3  4322032  116.0        40000        1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note : execute first step before proceeding\n",
    "import numpy as np\n",
    "\n",
    "# Second way, incluse them as feature\n",
    "houses['Outlier'] = np.where(houses['Rooms'] < 20, 0, 1)\n",
    "houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Square_Feet</th>\n",
       "      <th>Log_of_square_feet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>534433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>7.313220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392333</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2500</td>\n",
       "      <td>7.824046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>7.313220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4322032</td>\n",
       "      <td>116.0</td>\n",
       "      <td>40000</td>\n",
       "      <td>10.596635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Rooms  Square_Feet  Log_of_square_feet\n",
       "0   534433    2.0         1500            7.313220\n",
       "1   392333    3.5         2500            7.824046\n",
       "2   293222    2.0         1500            7.313220\n",
       "3  4322032  116.0        40000           10.596635"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note : execute first step before proceeding\n",
    "import numpy as np\n",
    "\n",
    "# Third way, transforming the features\n",
    "houses['Log_of_square_feet'] = [np.log(x) for x in houses['Square_Feet']]\n",
    "houses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Discretizing Features(NUmerical data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have numerical values and want to break them into discrete bins.<br>\n",
    "Depending on how we want to break up data, there are two techniques.<br>\n",
    "-> Binarize feature according to some threshold<br>\n",
    "-> Break up numerical values according to multiple thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binarize feature according to some threshold\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "# feature\n",
    "age = np.array([[6], [12], [20], [36], [65]])\n",
    "\n",
    "binarizer = Binarizer(18)\n",
    "\n",
    "transformed_age = binarizer.fit_transform(age)\n",
    "transformed_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Break up numerical values according to multiple thresholds\n",
    "\n",
    "second_transformed_age = np.digitize(age, bins=[20, 30, 40]) # right=True, includes bins as well\n",
    "second_transformed_age\n",
    "\n",
    "# Note : we can also use digitize to binarize, having only one bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Grouping observations using clustering(Numerical data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to cluster observations so that similar observations are grouped together. If we know, we have k groups, we can use k-means clustering to group similar observations and output a new feature containing each observation's group membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.877554</td>\n",
       "      <td>-3.336145</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-7.287210</td>\n",
       "      <td>-8.353986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6.943061</td>\n",
       "      <td>-7.023744</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7.440167</td>\n",
       "      <td>-8.791959</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.641388</td>\n",
       "      <td>-8.075888</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  group\n",
       "0  -9.877554  -3.336145      2\n",
       "1  -7.287210  -8.353986      0\n",
       "2  -6.943061  -7.023744      0\n",
       "3  -7.440167  -8.791959      0\n",
       "4  -6.641388  -8.075888      0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "features, _ = make_blobs(n_samples=50, n_features=2, centers=3, random_state=1)\n",
    "\n",
    "df = pd.DataFrame(features, columns=['feature_1', 'feature_2'])\n",
    "\n",
    "clusterer = KMeans(3, random_state=0)\n",
    "\n",
    "clusterer.fit(features)\n",
    "\n",
    "df['group'] = clusterer.predict(features)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Deleting Observations with Missing Values(Numerical data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1, 11.1],\n",
       "       [ 2.2, 22.2],\n",
       "       [ 3.3, 33.3],\n",
       "       [ 4.4, 44.4]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "features = np.array([[1.1, 11.1], [2.2, 22.2], [3.3, 33.3], [4.4, 44.4], [np.nan, 55]])\n",
    "\n",
    "# Keep only observations that are not (denoted by -) missing\n",
    "new_features = features[~np.isnan(features).any(axis=1)]\n",
    "\n",
    "new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.2</td>\n",
       "      <td>22.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.3</td>\n",
       "      <td>33.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.4</td>\n",
       "      <td>44.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2\n",
       "0        1.1       11.1\n",
       "1        2.2       22.2\n",
       "2        3.3       33.3\n",
       "3        4.4       44.4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternate way of dropping of mossing observations using Pandas\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(features, columns=['feature_1', 'feature_2'])\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Encoding nominal categorical features(Categorical data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a feature with nimonal classes that has no intrinsic ordering(e.g. apple, pear, banana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode the features using sklearn LabelBinarizer\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer\n",
    "\n",
    "feature = np.array([['Mumbai'], ['Bangalore'], ['New Delhi'], ['Kolkata'], ['Chennai']])\n",
    "\n",
    "one_hot = LabelBinarizer()\n",
    "\n",
    "new_feature = one_hot.fit_transform(feature)\n",
    "new_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bangalore', 'Chennai', 'Kolkata', 'Mumbai', 'New Delhi'],\n",
       "      dtype='<U9')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Different classes\n",
    "one_hot.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mumbai', 'Bangalore', 'New Delhi', 'Kolkata', 'Chennai'],\n",
       "      dtype='<U9')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reverse transform\n",
    "one_hot.inverse_transform(new_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bangalore</th>\n",
       "      <th>Chennai</th>\n",
       "      <th>Kolkata</th>\n",
       "      <th>Mumbai</th>\n",
       "      <th>New Delhi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Bangalore  Chennai  Kolkata  Mumbai  New Delhi\n",
       "0          0        0        0       1          0\n",
       "1          1        0        0       0          0\n",
       "2          0        0        0       0          1\n",
       "3          0        0        1       0          0\n",
       "4          0        1        0       0          0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternate way using Pandas\n",
    "import pandas as pd\n",
    "\n",
    "pd.get_dummies(feature[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Encoding nominal categorical features of multi-class(Categorical data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1],\n",
       "       [1, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 1],\n",
       "       [0, 0, 1, 1, 0],\n",
       "       [1, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclass_feature = [('Texas', 'Florida'), ('California', 'Alabama'), ('Texas', 'Florida'), ('Delware', 'Florida'), ('Texas', \"Alabama\")]\n",
    "\n",
    "one_hot_multiclass = MultiLabelBinarizer()\n",
    "\n",
    "new_multiclass_feature = one_hot_multiclass.fit_transform(multiclass_feature)\n",
    "\n",
    "new_multiclass_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alabama', 'California', 'Delware', 'Florida', 'Texas'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Different classes\n",
    "one_hot_multiclass.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Encoding Ordinal categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinal categorical features are ex:- high, medium, low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    2\n",
       "3    2\n",
       "4    3\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use of Pandas\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'Score' : ['Low', 'Low', 'Medium', 'Medium', 'High']})\n",
    "\n",
    "scale_mapper = {'Low':1, 'Medium':2, 'High':3}\n",
    "\n",
    "df = df['Score'].replace(scale_mapper)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    2\n",
       "3    2\n",
       "4    4\n",
       "5    3\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For more than 3 ordinal categorical features\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'Score' : ['Low', 'Low', 'Medium', 'Medium', 'High', 'Barely more than medium']})\n",
    "\n",
    "scale_mapper = {'Low':1, 'Medium':2, 'Barely more than medium':3, 'High':4}\n",
    "\n",
    "df = df['Score'].replace(scale_mapper)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    1.0\n",
       "2    2.0\n",
       "3    2.0\n",
       "4    4.0\n",
       "5    2.2\n",
       "Name: Score, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For more than 3 ordinal categorical features\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'Score' : ['Low', 'Low', 'Medium', 'Medium', 'High', 'Barely more than medium']})\n",
    "\n",
    "scale_mapper = {'Low':1, 'Medium':2, 'Barely more than medium':2.2, 'High':4}\n",
    "\n",
    "df = df['Score'].replace(scale_mapper)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Encoding dictionaries of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a dicionary and want to convert into a feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 2., 0.],\n",
       "       [3., 4., 0.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 2., 2.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "data_dict = [{'Red':2,'Blue':4}, {'Red':4, 'Blue':3}, {'Red':1, 'Yellow':2},{'Red':2, 'Yellow':2}]\n",
    "\n",
    "dict_vectorizer = DictVectorizer(sparse=False)\n",
    "\n",
    "features = dict_vectorizer.fit_transform(data_dict)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Blue', 'Red', 'Yellow']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Basic Cleaning of Given Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Remove whitespaces\n",
    "2. Remove periods '.'\n",
    "3. Convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Anskhoiuhc. By aoihouhoie HJkoiojueiujbh',\n",
       " 'Pakiuguiyvc iyubviygiy. uhiu',\n",
       " 'Ueiyvuc kaushiuhi asiuhi. aiugiuy']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given text\n",
    "text_data = ['    Anskhoiuhc. By aoihouhoie HJkoiojueiujbh    ', \n",
    "             'Pakiuguiyvc iyubviygiy. uhiu', '     Ueiyvuc kaushiuhi asiuhi. aiugiuy    ']\n",
    "\n",
    "# Strip whitespaces\n",
    "strip_whitespace = [a.strip() for a in text_data]\n",
    "strip_whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Anskhoiuhc By aoihouhoie HJkoiojueiujbh',\n",
       " 'Pakiuguiyvc iyubviygiy uhiu',\n",
       " 'Ueiyvuc kaushiuhi asiuhi aiugiuy']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove periods '.'\n",
    "remove_periods = [a.replace('.','') for a in strip_whitespace]\n",
    "remove_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anskhoiuhc by aoihouhoie hjkoiojueiujbh',\n",
       " 'pakiuguiyvc iyubviygiy uhiu',\n",
       " 'ueiyvuc kaushiuhi asiuhi aiugiuy']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to lowercase\n",
    "lowercase = [a.lower() for a in remove_periods]\n",
    "lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Parsing and Cleaning HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have text data with HTML elements and want to extract just the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal et Communication\n",
      "Ingénierie Réseaux et Télécommunications\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "text = '''\n",
    "<td><a href=\"http://www.irit.fr/SC\">Signal et Communication</a>\n",
    "<br/><a href=\"http://www.irit.fr/IRT\">Ingénierie Réseaux et Télécommunications</a>\n",
    "</td>\n",
    "'''\n",
    "soup = BeautifulSoup(text)\n",
    "\n",
    "print(soup.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Welcome to Machine learning for beginners'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# punctuation marks \n",
    "punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "\n",
    "text = \"Welcome???@@##$ to#$% Machine%$^ learning$%^& for beginners\"\n",
    "\n",
    "for x in text.lower():\n",
    "    if x in punctuations:\n",
    "        text = text.replace(x, '')\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. Tokenizing Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Tokenizing into words\n",
    "2. Tokenizing into sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have text and break into individual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'is', 'good', 'reference', 'for', 'machine', 'learning', 'operations']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizing into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"This is good reference for machine learning operations\"\n",
    "\n",
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi how are you.',\n",
       " 'I am fine how about you.',\n",
       " 'Me too fine.',\n",
       " 'Nice to meet you.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizing into sentences\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "text = \"Hi how are you. I am fine how about you. Me too fine. Nice to meet you.\"\n",
    "\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Removing Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given text data remove extremely common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'good', 'reference', 'machine', 'learning', 'operations']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"This is good reference for machine learning operations\"\n",
    "text = word_tokenize(text)\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "cleaned_text = [word for word in text if word not in stop_words]\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we want to see first 10 stopwords\n",
    "stop_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Stemming words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before stemming :\n",
      "['i', 'am', 'humbl', 'by', 'thi', 'tradit', 'meet']\n",
      "\n",
      "\n",
      "After stemming :\n",
      "['i', 'am', 'humbl', 'by', 'thi', 'tradit', 'meet']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "tokenized_words = ['i', 'am', 'humbled', 'by', 'this', 'traditional', 'meeting']\n",
    "print('Before stemming :')\n",
    "print(stemmed_words)\n",
    "print('\\n')\n",
    "porter = PorterStemmer()\n",
    "\n",
    "stemmed_words = [porter.stem(word) for word in tokenized_words]\n",
    "print('After stemming :')\n",
    "print(stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. Encoding Text as Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have text data and want to create a set of features indicating the number of times an observation's text contains a particular word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x5 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text_data = np.array(['Machine learning', 'Deep learning', 'Artificial Intelligence'])\n",
    "\n",
    "count = CountVectorizer()\n",
    "bag_of_words = count.fit_transform(text_data)\n",
    "\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1],\n",
       "       [0, 1, 0, 1, 0],\n",
       "       [1, 0, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words = bag_of_words.toarray()\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artificial', 'deep', 'intelligence', 'learning', 'machine']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting feature names\n",
    "count.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'machine': 4, 'learning': 3, 'deep': 1, 'artificial': 0, 'intelligence': 2}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. Encoding Text with Weighing word importance(TFIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "text_data = np.array(['Machine learning', 'Deep learning', 'Artificial Intelligence'])\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "feature_matrix = tfidf.fit_transform(text_data)\n",
    "feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.60534851, 0.79596054],\n",
       "       [0.        , 0.79596054, 0.        , 0.60534851, 0.        ],\n",
       "       [0.70710678, 0.        , 0.70710678, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artificial', 'deep', 'intelligence', 'learning', 'machine']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'machine': 4, 'learning': 3, 'deep': 1, 'artificial': 0, 'intelligence': 2}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. Reducing Features using Principal Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given set of features reduce the number of features while retaining the variance of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -0.33501649, -0.04308102, ..., -1.14664746,\n",
       "        -0.5056698 , -0.19600752],\n",
       "       [ 0.        , -0.33501649, -1.09493684, ...,  0.54856067,\n",
       "        -0.5056698 , -0.19600752],\n",
       "       [ 0.        , -0.33501649, -1.09493684, ...,  1.56568555,\n",
       "         1.6951369 , -0.19600752],\n",
       "       ...,\n",
       "       [ 0.        , -0.33501649, -0.88456568, ..., -0.12952258,\n",
       "        -0.5056698 , -0.19600752],\n",
       "       [ 0.        , -0.33501649, -0.67419451, ...,  0.8876023 ,\n",
       "        -0.5056698 , -0.19600752],\n",
       "       [ 0.        , -0.33501649,  1.00877481, ...,  0.8876023 ,\n",
       "        -0.26113572, -0.19600752]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "features = StandardScaler().fit_transform(digits.data)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.70631939, -0.39512814, -1.73816236, ...,  0.36526417,\n",
       "        -0.31369006,  0.05355504],\n",
       "       [ 0.21732591,  0.38276482,  1.72878893, ..., -0.17818068,\n",
       "        -0.14031747,  1.18179755],\n",
       "       [ 0.4804351 , -0.13130437,  1.33172761, ..., -0.01924571,\n",
       "        -0.23580029,  0.92966158],\n",
       "       ...,\n",
       "       [ 0.37732433, -0.0612296 ,  1.0879821 , ..., -1.05526847,\n",
       "         1.75559618, -0.87894699],\n",
       "       [ 0.39705007, -0.15768102, -1.08160094, ...,  0.10442881,\n",
       "         0.65907949,  1.1292155 ],\n",
       "       [-0.46407544, -0.92213976,  0.12493334, ..., -1.10593026,\n",
       "         0.54434185, -0.26573597]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=0.99, whiten=True)\n",
    "\n",
    "features_pca = pca.fit_transform(features)\n",
    "features_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features : 64\n",
      "Reduced number of features : 54\n"
     ]
    }
   ],
   "source": [
    "print('Original number of features :', features.shape[1])\n",
    "print('Reduced number of features :', features_pca.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23. Thresholding Numerical Feature Variance (Dimensionality reduction technique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a set of numerical features and want to remove those with low variance(ie. likely containing little information). Need to select subset of features with variances above given threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 1.4, 0.2],\n",
       "       [4.9, 1.4, 0.2],\n",
       "       [4.7, 1.3, 0.2]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "thresholder = VarianceThreshold(threshold=0.5)\n",
    "\n",
    "features_high_variance = thresholder.fit_transform(features)\n",
    "\n",
    "features_high_variance[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data matrix :\n",
      " [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]]\n",
      "\n",
      "\n",
      "High variance data matrix :\n",
      " [[5.1 1.4 0.2]\n",
      " [4.9 1.4 0.2]\n",
      " [4.7 1.3 0.2]]\n"
     ]
    }
   ],
   "source": [
    "print('Original data matrix :\\n', features[0:3])\n",
    "print('\\n')\n",
    "print('High variance data matrix :\\n', features_high_variance[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variances of different features :\n",
      "\n",
      "[0.68112222 0.18871289 3.09550267 0.57713289]\n"
     ]
    }
   ],
   "source": [
    "print('Variances of different features :\\n')\n",
    "print(thresholder.variances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24. Thresholding binary feature variance(dimensionality reduction technique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a set of binary categorical features and want to remove those with low variance(ie. likely containing little information). Select a subset of features with a Bernoulli random variable variance above a given threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "features = [[0, 1, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1], [1, 0, 0]]\n",
    "\n",
    "thresholder = VarianceThreshold(threshold=(0.75*(1-0.75))) \n",
    "\n",
    "thresholder.fit_transform(features)\n",
    "\n",
    "# note : In binary features ie. Bernoulli random variable variance is calculated as Var(x)=p(1-p)\n",
    "#        where p is the proportion of observations of class 1. Hence by setting p, we can remove\n",
    "#        features where the vast majority of observations are one class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25. Handling Highly Correlated features(dimensionality reduction technique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a feature matrix and suspect some features are highly correlated. Using this correlation matrix to check highly correlated features. If highly correlated features exists, consider dropping one of the correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1],\n",
       "       [2, 2, 0],\n",
       "       [3, 3, 1],\n",
       "       [4, 4, 0],\n",
       "       [5, 5, 1],\n",
       "       [6, 6, 0],\n",
       "       [7, 7, 1],\n",
       "       [8, 7, 0]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "features = np.array([[1, 1, 1], [2, 2, 0], [3, 3, 1], [4, 4, 0], [5, 5, 1], [6, 6, 0], [7, 7, 1], [8, 7, 0]])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2\n",
       "0  1  1  1\n",
       "1  2  2  0\n",
       "2  3  3  1\n",
       "3  4  4  0\n",
       "4  5  5  1\n",
       "5  6  6  0\n",
       "6  7  7  1\n",
       "7  8  7  0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert feature matrix into dataframe\n",
    "df = pd.DataFrame(features)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991837</td>\n",
       "      <td>0.218218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.991837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.177084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.218218</td>\n",
       "      <td>0.177084</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0  1.000000  0.991837  0.218218\n",
       "1  0.991837  1.000000  0.177084\n",
       "2  0.218218  0.177084  1.000000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create correlation matrix\n",
    "corr_matrix = df.corr().abs()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.991837</td>\n",
       "      <td>0.218218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.177084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2\n",
       "0 NaN  0.991837  0.218218\n",
       "1 NaN       NaN  0.177084\n",
       "2 NaN       NaN       NaN"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  2\n",
       "0  1  1\n",
       "1  2  0\n",
       "2  3  1\n",
       "3  4  0\n",
       "4  5  1"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find index of feature columns with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column]>0.95)]\n",
    "df.drop(df.columns[to_drop], axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 26. Removing Irrelavant Features for Classification(dimensionality reduction technique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have categorical target vector and want to remove uninformative features.\n",
    "1. If the features are categorical, calculate chi-square statistic between each feature and the target vector.\n",
    "2. If the features are quantitative, compute the ANOVA F-value between each feature and the target vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original no. of features : 4\n",
      "Reduced no. of features : 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# convert to categorical data by converting data to integers\n",
    "features = features.astype(int)\n",
    "\n",
    "# select two features with highest chi-squared statistics\n",
    "chi2_selector = SelectKBest(chi2, k=2)\n",
    "features_kbest = chi2_selector.fit_transform(features, target)\n",
    "\n",
    "print('Original no. of features :', features.shape[1])\n",
    "print('Reduced no. of features :', features_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original no. of features : 4\n",
      "Reduced no. of features : 2\n"
     ]
    }
   ],
   "source": [
    "# If the features are quantitative, compute the ANOVA F-value between each feature and the target vector\n",
    "fvalue_selector = SelectKBest(f_classif, k=2)\n",
    "features_kbest = fvalue_selector.fit_transform(features, target)\n",
    "\n",
    "print('Original no. of features :', features.shape[1])\n",
    "print('Reduced no. of features :', features_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27. Cross Validating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to evaluate how well our model will work in the real world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9693916821849783"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# create feature matrix\n",
    "features = digits.data\n",
    "\n",
    "# create target vector\n",
    "target = digits.target\n",
    "\n",
    "# create standardizer\n",
    "standardizer = StandardScaler()\n",
    "\n",
    "# create logistic regression object\n",
    "logistic = LogisticRegression()\n",
    "\n",
    "# create a pipeline that standardizes, then runs logistic regression\n",
    "pipeline = make_pipeline(standardizer, logistic)\n",
    "\n",
    "# create k-fild cv\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# conduct k-fold cv\n",
    "cv_results = cross_val_score(pipeline, features, target, cv=kf, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# calculate mean\n",
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97777778, 0.98888889, 0.96111111, 0.94444444, 0.97777778,\n",
       "       0.98333333, 0.95555556, 0.98882682, 0.97765363, 0.93854749])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28. Create a Baseline Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want a simple baseline regression model to complare against your model. Sklearn's DummtRegressor helps here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.001119359203955339"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "boston = load_boston()\n",
    "\n",
    "# create features\n",
    "features, target = boston.data, boston.target\n",
    "\n",
    "# train test split\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, random_state=0)\n",
    "\n",
    "# create a dummy regressor\n",
    "dummy = DummyRegressor(strategy='mean')\n",
    "\n",
    "# train dummy regressor\n",
    "dummy.fit(features_train, target_train)\n",
    "\n",
    "# get R-squared score\n",
    "dummy.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6354638433202114"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To compare, we train out model and evaluate the performance score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "ols = LinearRegression()\n",
    "ols.fit(features_train, target_train)\n",
    "\n",
    "# R-squared score\n",
    "ols.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 29. Create a Baseline Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42105263157894735"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "boston = load_iris()\n",
    "\n",
    "# create features\n",
    "features, target = iris.data, iris.target\n",
    "\n",
    "# train test split\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, random_state=0)\n",
    "\n",
    "# create a dummy regressor\n",
    "dummy = DummyClassifier(strategy='uniform', random_state=1)\n",
    "\n",
    "# train dummy regressor\n",
    "dummy.fit(features_train, target_train)\n",
    "\n",
    "# get R-squared score\n",
    "dummy.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To compare, we train out model and evaluate the performance score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(features_train, target_train)\n",
    "\n",
    "# R-squared score\n",
    "classifier.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30. Evaluating Binary Classifier Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9555, 0.95  , 0.9585, 0.9555, 0.956 ])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=10000, n_features=3, n_informative=3, n_redundant=0, n_classes=2, random_state=1)\n",
    "\n",
    "logistic = LogisticRegression()\n",
    "\n",
    "cross_val_score(logistic, X, y, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95963673, 0.94820717, 0.9635996 , 0.96149949, 0.96060606])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(logistic, X, y, scoring = 'precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.951, 0.952, 0.953, 0.949, 0.951])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(logistic, X, y, scoring = 'recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95529884, 0.9500998 , 0.95827049, 0.95520886, 0.95577889])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(logistic, X, y, scoring = 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.947"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using CV if we have true y values and the predicted y values. We can calculate metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "\n",
    "y_hat = logistic.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 31. Evaluating Binary Classifier Thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to evaluate a binary classifier and various probability thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# create feature matrix and target vector\n",
    "features, target = make_classification(n_samples=10000, n_features=10, n_classes=2, n_informative=3, random_state=3)\n",
    "\n",
    "# split into training and test sets\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# create classifier\n",
    "logistic = LogisticRegression()\n",
    "\n",
    "# train model\n",
    "logistic.fit(features_train, target_train)\n",
    "\n",
    "# get predicted probabilities\n",
    "target_probabilities = logistic.predict_proba(features_test)[:,1]\n",
    "\n",
    "false_positive_rate, true_positive_rate, threshold = roc_curve(target_test, target_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(false_positive_rate, true_positive_rate)\n",
    "plt.plot([0, 1], ls=\"--\")\n",
    "plt.plot([0, 0], [1, 0], c=\".7\"), plt.plot([1, 1], c=\".7\")\n",
    "plt.ylabel(\"True +ve rate\")\n",
    "plt.xlabel(\"False +ve rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 32. Evaluating Multicalss Classifier Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a model that predicts three or more classes and want to evaluate its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.841 , 0.829 , 0.8265, 0.8155, 0.82  ])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# generate feature matrix and target vector\n",
    "features, target = make_classification(n_samples=10000, n_features=3, n_informative=3, n_redundant=0, n_classes=3, random_state=1)\n",
    "\n",
    "# create logistic regression\n",
    "logistic = LogisticRegression()\n",
    "\n",
    "# cross-validate model using accuracy\n",
    "cross_val_score(logistic, features, target, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.841 , 0.829 , 0.8265, 0.8155, 0.82  ])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross-validate model using accuracy and parallel processing\n",
    "cross_val_score(logistic, features, target, scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.841 , 0.829 , 0.8265, 0.8155, 0.82  ])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross-validate model using f1 micro\n",
    "cross_val_score(logistic, features, target, scoring='f1_micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 33. Visualizing a Classifier's Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given predicted classes and true classes of the test data, want to visually compare model's quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shashi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       2, 0, 2, 1, 0, 0, 1, 2, 1, 2, 1, 2, 2, 0, 1, 0])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# create feature matrix\n",
    "features = iris.data\n",
    "\n",
    "# create target vector\n",
    "target = iris.target\n",
    "\n",
    "# create alist of target classnames\n",
    "class_names = iris.target_names\n",
    "\n",
    "# create training and test sets\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, random_state=1)\n",
    "\n",
    "# create logostic regression\n",
    "logistic = LogisticRegression()\n",
    "\n",
    "# train model and make predictions\n",
    "target_predicted = logistic.fit(features_train, target_train).predict(features_test)\n",
    "\n",
    "target_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  0,  0],\n",
       "       [ 0, 15,  1],\n",
       "       [ 0,  0,  9]], dtype=int64)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create confuction matrix\n",
    "matrix = confusion_matrix(target_test, target_predicted)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>setosa</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>versicolor</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virginica</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            setosa  versicolor  virginica\n",
       "setosa          13           0          0\n",
       "versicolor       0          15          1\n",
       "virginica        0           0          9"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# create pandas dataframe\n",
    "df = pd.DataFrame(matrix, index=class_names, columns=class_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create heatmap\n",
    "sns.heatmap(df, annot=True, cbar=None, cmap='Blues')\n",
    "plt.title(\"Confuction matrix\")\n",
    "plt.tight_layout()\n",
    "plt.ylabel(\"True Class\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
